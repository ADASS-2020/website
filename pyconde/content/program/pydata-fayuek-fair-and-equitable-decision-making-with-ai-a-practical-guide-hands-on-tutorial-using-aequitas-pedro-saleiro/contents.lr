_model: session 
---
code: FAYUEK
---
title: Fair and equitable decision-making with AI: a practical guide & hands-on tutorial using Aequitas
---
description: In this tutorial, we are going to deep dive into algorithmic fairness, from metrics and definitions to practical case studies, including bias audits using Aequitas (http://github.com/dssg/aequitas) in real policy problems where AI is being used
---
twitter_image: /static/media/twitter/FAYUEK.jpg
---
speakers: Pedro Saleiro
---
submission_type: Tutorial - 90 Min.
---
domains: Data Science â€¢ Machine Learning
---
biography: #### Pedro Saleiro

Affiliation: University of Chicago



Pedro Saleiro is a post-doc at the University of Chicago working with Rayid Ghani at the Center for Data Science and Public Policy. He is doing data science projects with government and non-profit partners in policy areas such as criminal justice, healthcare and future of workforce. At the same time Pedro is developing new methods and open-source tools to detect and explain bias and discrimination in machine learning models. Before joining UChicago, Pedro completed his PhD in Machine Learning for IR and NLP at the University of Porto, Portugal.

[Homepage](https://dsapp.uchicago.edu/projects/aequitas/)
---
affiliation: University of Chicago
---
track: PyData
---
body: Recent work has raised concerns on the risk of unintended bias in AI systems being used nowadays that can affect individuals unfairly based on race, gender or religion, among other possible characteristics.
While a lot of bias metrics and fairness definitions have been proposed in recent years, there is no consensus on which metric/definition should be used and there are very few available resources
to operationalize them. Therefore, despite recent awareness, auditing for bias and fairness when developing and deploying AI systems is not yet a standard practice. In this tutorial, we present Aequitas(http://github.com/dssg/aequitas), an open source bias and fairness audit toolkit that is an intuitive and easy to use addition to the machine learning workflow, enabling users to seamlessly test models for several bias
and fairness metrics in relation to multiple population sub-groups. Aequitas facilitates informed and equitable decisions around developing and deploying algorithmic decision making systems for both data scientists, machine learning researchers and policymakers.

In this tutorial we will cover the following how tos: 
*How to think about fairness and equity when building and evaluating AI systems;* *How to define fairness goals and manage efficiency and effectiveness tradeoffs;* *How to select fairness metrics;* *How to build and select ML models that achieve those fairness goals; * *How to validate that the AI system is fair*;*How to monitor a deployed AI system for fairness and adapt if necessary;*

